{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate application using manual data set\n",
    "\n",
    "## Objective\n",
    "\n",
    "This lab provides a step-by-step guide on how to application endpoints deployed using manual data set\n",
    "\n",
    "Documentation about evaluation SDK - [azure-ai-evaluation](https://learn.microsoft.com/en-us/azure/ai-studio/how-to/develop/evaluate-sdk)\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "### Installation\n",
    "\n",
    "Install the following packages required to execute this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-ai-evaluation\n",
    "%pip install promptflow-azure\n",
    "%pip install azure-identity\n",
    "%pip install --upgrade openai\n",
    "%pip install marshmallow\n",
    "%pip install python-dotenv\n",
    "%pip install azure-ai-evaluation[remote]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters and imports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by load the configuration from .env file created from the previous step. We also print out the config value for validation. \n",
    "For simplicity, we use key based authentication however Azure AI SDK also support managed indentity. \n",
    "If you hasnt create one please check the [README](README.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Environment variables loaded successfully.\")\n",
    "print(f\"{os.environ['AZURE_OPENAI_API_VERSION']}\")\n",
    "print(f\"{os.environ['AZURE_OPENAI_DEPLOYMENT']}\")\n",
    "print(f\"{os.environ['AZURE_OPENAI_ENDPOINT']}\")\n",
    "print(f\"{os.environ['AZURE_OPENAI_KEY']}\")\n",
    "print(f\"{os.environ['AZURE_AI_FOUNDRY_RESOURCE_GROUP']}\")\n",
    "print(f\"{os.environ['APPLICATION_ENDPOINT']}\")\n",
    "print(f\"{os.environ['APPLICATION_KEY']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target Application\n",
    "\n",
    "We will use Evaluate API provided by Azure AI Evaluation SDK. It requires a target endpoint or python Function, which handles a call the application endpoint or a LLM inference endpoint.\n",
    "In this lab we use [application_endpoint.py](application_endpoint.py) to call to a application API.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Following code reads Json file \"manual_data.jsonl\" which contains inputs to the application endpoint function. It provides question, context and ground truth on each line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\"manual_data.jsonl\", lines=True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "To use AI Assisted Evaluator, we will an LLM model details as a Judge that can be passed as model config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_config = {\n",
    "    \"azure_endpoint\": os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    \"azure_deployment\": os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "    \"api_key\": os.environ.get(\"AZURE_OPENAI_KEY\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualise the output, we need to provide Azure AI Project details so that traces and eval results are pushing in the project in Azure AI Studio. NOTE: This is not compulsory to use Azure AI Evaluation SDK. AI Evaluation SDK output the evaluation result so that can be use in CICD pipeline like traditional unit test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_project = {\n",
    "    \"subscription_id\": os.environ[\"AZURE_SUBSCRIPTION_ID\"],\n",
    "    \"resource_group_name\": os.environ[\"AZURE_AI_FOUNDRY_RESOURCE_GROUP\"],\n",
    "    \"project_name\": os.environ[\"AZURE_AI_FOUNDRY_PROJECT_NAME\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the evaluation\n",
    "\n",
    "The Following code runs Evaluate API and uses Content Safety and other metric such as Groundedness to evaluate results from different models.\n",
    "\n",
    "The following are the few parameters required by Evaluate API. \n",
    "\n",
    "+   Data file: It represents data file 'manual_data.jsonl' in JSON format. Each line contains question, context and ground truth for evaluators.     \n",
    "\n",
    "+   Application Target: It is name of python class which can route the calls to specific application endpoints \n",
    "\n",
    "+   Evaluators: List of evaluators is provided, to evaluate given prompts (questions) as input and output (answers) from LLM models. \n",
    "\n",
    "NOTE: If you have error about access storage account please enable key access for your storage account.\n",
    "<details>\n",
    "    <img width=\"500px\" height=\"500px\" src=\"storageconfiguration.png\" alt=\"Storage Account Configuration\" />\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PF_LOGGING_LEVEL'] = 'DEBUG'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "from azure.ai.evaluation import evaluate\n",
    "from azure.ai.evaluation import (\n",
    "    ContentSafetyEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    GroundednessEvaluator,\n",
    "    FluencyEvaluator,\n",
    "    SimilarityEvaluator,\n",
    "    GroundednessProEvaluator,\n",
    "    IndirectAttackEvaluator,\n",
    ")\n",
    "from application_endpoint import ApplicationEndpoint\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "content_safety_evaluator = ContentSafetyEvaluator(\n",
    "    azure_ai_project=azure_ai_project, credential=DefaultAzureCredential()\n",
    ")\n",
    "relevance_evaluator = RelevanceEvaluator(model_config)\n",
    "coherence_evaluator = CoherenceEvaluator(model_config)\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config)\n",
    "groundedness_pro_eval = GroundednessProEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "\n",
    "fluency_evaluator = FluencyEvaluator(model_config)\n",
    "similarity_evaluator = SimilarityEvaluator(model_config)\n",
    "indirect_attack_evaluator = IndirectAttackEvaluator(azure_ai_project=azure_ai_project, credential=DefaultAzureCredential())\n",
    "\n",
    "path = str(pathlib.Path(pathlib.Path.cwd())) + \"/manual_data.jsonl\"\n",
    "\n",
    "current_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "evaluation_name = f\"Manual-Data-Eval-Run-{current_date}\"\n",
    "\n",
    "results = evaluate(\n",
    "    evaluation_name=evaluation_name,\n",
    "    data=path,\n",
    "    target=ApplicationEndpoint(),\n",
    "    evaluators={\n",
    "        \"content_safety\": content_safety_evaluator,\n",
    "        \"coherence\": coherence_evaluator,\n",
    "        \"relevance\": relevance_evaluator,\n",
    "        \"groundedness\": groundedness_evaluator,\n",
    "        \"fluency\": fluency_evaluator,\n",
    "        \"similarity\": similarity_evaluator,\n",
    "        \"groundedness_pro\": groundedness_pro_eval,\n",
    "        \"indirect_attack\": indirect_attack_evaluator,\n",
    "    },\n",
    "    azure_ai_project=azure_ai_project,\n",
    "    evaluator_config={\n",
    "        \"content_safety\": {\"column_mapping\": {\"query\": \"${data.query}\", \"response\": \"${target.response}\"}},\n",
    "        \"coherence\": {\"column_mapping\": {\"response\": \"${target.response}\", \"query\": \"${data.query}\"}},\n",
    "        \"relevance\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"groundedness\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${target.response}\",\n",
    "                \"context\": \"${data.context}\",\n",
    "                \"query\": \"${data.query}\",\n",
    "            }\n",
    "        },\n",
    "        \"groundedness_pro\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${target.response}\",\n",
    "                \"context\": \"${data.context}\",\n",
    "                \"query\": \"${data.query}\",\n",
    "            }\n",
    "        },\n",
    "        \"indirect_attack\": {\n",
    "            \"column_mapping\": {\n",
    "                \"response\": \"${target.response}\",\n",
    "                \"query\": \"${data.query}\",\n",
    "            }\n",
    "        },\n",
    "        \"fluency\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "        \"similarity\": {\n",
    "            \"column_mapping\": {\"response\": \"${target.response}\", \"context\": \"${data.context}\", \"query\": \"${data.query}\"}\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View the results as output of the Evaluate API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results[\"rows\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can view detail result in AI Project for quality also risk and safety environments.\n",
    "<img width=\"60%\" height=\"60%\" src=\"aifoundryevaltab.png\" alt=\"Ai Foundry SDK\" />\n",
    "\n",
    "<img width=\"60%\" height=\"60%\" src=\"evalrundetail.png\" alt=\"Ai Foundry SDK\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
